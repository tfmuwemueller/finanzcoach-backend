# -*- coding: utf-8 -*-
"""trading_tool1-1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1EyfaNs70Dxx2fLpeOoZe7fWyAR08JvFF
"""

!pip install yfinance requests beautifulsoup4 openai scikit-learn tensorflow flask pyngrok pycoingecko requests-cache alpha_vantage fredapi praw tweepy

import logging

logging.basicConfig(
    filename='analyse_logs.log',
    level=logging.ERROR,
    format='%(asctime)s:%(levelname)s:%(message)s'
)

import yfinance as yf
import numpy as np
import pandas as pd
import requests
from bs4 import BeautifulSoup
import openai
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LSTM, Input
from flask import Flask, jsonify
from pyngrok import ngrok
from fredapi import Fred
import logging
import os
from alpha_vantage.timeseries import TimeSeries
from alpha_vantage.fundamentaldata import FundamentalData
from fredapi import Fred
import praw

# Sichere Nutzung der API-Keys √ºber Environment Variables
openai.api_key = os.environ.get('OPENAI_API_KEY')
ALPHA_API_KEY = os.environ.get('ALPHA_API_KEY')
FRED_API_KEY = os.environ.get('FRED_API_KEY')
FINNHUB_API_KEY = os.environ.get('FINNHUB_API_KEY')

fred = Fred(api_key=FRED_API_KEY)

reddit = praw.Reddit(
    client_id=os.environ.get('REDDIT_CLIENT_ID'),
    client_secret=os.environ.get('REDDIT_SECRET'),
    user_agent=os.environ.get('REDDIT_USER_AGENT')
)


# OpenAI API-Key
OPENAI_API_KEY = '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'
openai.api_key = OPENAI_API_KEY

# pyngrok API-Key
ngrok.set_auth_token("2wWxiXxLoZzRma3ssIxq2jz5Wbd_5iufwnc2KQRjkGg9EdA1m")

# FRED StLouis API-Key
FRED_API_KEY = '4559ec6ea165bf4b0576824600e75997'
fred = Fred(api_key=FRED_API_KEY)

from pycoingecko import CoinGeckoAPI
cg = CoinGeckoAPI()

def get_crypto_data(ticker, days=365):  # Maximal 1 Jahr Datenhistorie erlaubt
    coin_data = cg.get_coin_market_chart_by_id(id=ticker, vs_currency='usd', days=days)
    prices = [price[1] for price in coin_data['prices']]
    return prices

from alpha_vantage.timeseries import TimeSeries
import pandas as pd

API_KEY = "87WSBSVKINDJN89S"

def get_alpha_vantage_data(ticker):
    ts = TimeSeries(key=API_KEY, output_format='pandas')
    data, meta_data = ts.get_daily(symbol=ticker, outputsize='full')
    return data

from alpha_vantage.fundamentaldata import FundamentalData

API_KEY = "87WSBSVKINDJN89S"  # Alpha Vantage API-Key

def get_alpha_vantage_dividend(ticker):
    fd = FundamentalData(key=API_KEY, output_format='json')
    try:
        overview, _ = fd.get_company_overview(symbol=ticker)
        dividend_yield = overview.get("DividendYield")
        if dividend_yield:
            return float(dividend_yield) * 100  # Prozent
        else:
            return "N/A"
    except Exception as e:
        return f"Fehler: {e}"

def get_stock_data(ticker, period="5y"):
    df = yf.download(ticker, period=period, auto_adjust=True)
    if df.empty:
        print("‚ö†Ô∏è Keine Daten gefunden!")
        return df

    # Technische Indikatoren
    df['MA50'] = df['Close'].rolling(window=50).mean()
    df['MA100'] = df['Close'].rolling(window=100).mean()
    df['MA200'] = df['Close'].rolling(window=200).mean()

    # RSI Berechnung
    delta = df['Close'].diff(1)
    up = delta.clip(lower=0)
    down = -1 * delta.clip(upper=0)
    ema_up = up.ewm(com=13, adjust=False).mean()
    ema_down = down.ewm(com=13, adjust=False).mean()
    rs = ema_up / ema_down
    df['RSI'] = 100 - (100 / (1 + rs))

    df.dropna(inplace=True)
    return df

def get_etf_data(ticker, period='3y'):
    df = yf.download(ticker, period=period, auto_adjust=True)
    df.reset_index(inplace=True)
    return df

import requests

FINNHUB_API_KEY = 'd0baj5pr01qo0h63gjjgd0baj5pr01qo0h63gjk0'

def get_dividend_finnhub(ticker):
    url = f'https://finnhub.io/api/v1/stock/metric?symbol={ticker}&metric=all&token={FINNHUB_API_KEY}'

    response = requests.get(url)
    data = response.json()

    try:
        dividend_yield = data['metric']['dividendYieldIndicatedAnnual']
        if dividend_yield is not None:
            return float(dividend_yield)
        else:
            return "N/A"
    except (KeyError, TypeError):
        return "N/A"

from alpha_vantage.timeseries import TimeSeries

ALPHA_API_KEY = 'dein_alpha_vantage_api_key'

def get_bond_data(symbol, outputsize='full'):
    ts = TimeSeries(key=ALPHA_API_KEY, output_format='pandas')
    data, _ = ts.get_daily(symbol=symbol, outputsize=outputsize)
    data.reset_index(inplace=True)
    data.rename(columns={
        'date': 'Date',
        '1. open': 'Open',
        '2. high': 'High',
        '3. low': 'Low',
        '4. close': 'Close',
        '5. volume': 'Volume'
    }, inplace=True)
    return data

import functools
import logging
import time
import yfinance as yf

@functools.lru_cache(maxsize=100)
def get_fundamentals(ticker, full_name):
    stock = yf.Ticker(ticker)

    info = {}
    try:
        info = stock.info
    except yf.YFRateLimitError:
        logging.warning(f"Rate Limit erreicht f√ºr {ticker}, warte 10 Sekunden und versuche erneut...")
        time.sleep(10)
        try:
            info = stock.info
        except Exception as e:
            logging.error(f"Erneuter Fehler bei Yahoo-Abfrage f√ºr {ticker}: {str(e)}")
            info = {}
    except Exception as e:
        logging.error(f"Allgemeiner Fehler bei Yahoo-Abfrage f√ºr {ticker}: {str(e)}")
        info = {}

    yahoo_dividend = info.get("dividendYield", 0) * 100 if info.get("dividendYield") else "N/A"

    try:
        alpha_dividend = get_alpha_vantage_dividend(ticker)
    except Exception as e:
        logging.error(f"Fehler Alpha Vantage Dividend {ticker}: {str(e)}")
        alpha_dividend = "N/A"

    try:
        finnhub_dividend = get_dividend_finnhub(ticker)
    except Exception as e:
        logging.error(f"Fehler Finnhub Dividend {ticker}: {str(e)}")
        finnhub_dividend = "N/A"

    # GPT-Validierung
    try:
        dividend_validation = validate_dividend_extended(yahoo_dividend, alpha_dividend, finnhub_dividend)
    except Exception as e:
        logging.error(f"Fehler bei GPT-Dividendenvalidierung {ticker}: {str(e)}")
        dividend_validation = f"GPT-Validierung Fehler: {str(e)}"

    fundamentals = {
        "KGV": info.get("trailingPE", "N/A"),
        "Dividendenrendite (%) Yahoo": yahoo_dividend,
        "Dividendenrendite (%) Alpha": alpha_dividend,
        "Dividendenrendite (%) Finnhub": finnhub_dividend,
        "Dividenden-Validierung (GPT)": dividend_validation,
        "Marktkapitalisierung (Mrd.)": info.get("marketCap", 0) / 1e9 if info.get("marketCap") else "N/A",
        "Branche (vorl√§ufig)": info.get("industry", "N/A"),
        "ESG-Score": info.get("esgScore", "N/A")
    }

    # GPT-Klassifizierung der Branche
    try:
        gpt_response = openai.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "Klassifiziere pr√§zise Branche und ESG-Relevanz."},
                {"role": "user", "content": f"Unternehmen: {full_name}, Branche: {fundamentals['Branche (vorl√§ufig)']}"}
            ]
        )
        fundamentals["Branche (GPT)"] = gpt_response.choices[0].message.content.strip()
    except Exception as e:
        logging.error(f"Fehler GPT Branchen-Klassifizierung {ticker}: {str(e)}")
        fundamentals["Branche (GPT)"] = f"GPT-Fehler: {str(e)}"

    return fundamentals

def validate_dividend_extended(yahoo_div, alpha_div, finnhub_div):
    yahoo_div = yahoo_div if isinstance(yahoo_div, (int, float)) else "N/A"
    alpha_div = alpha_div if isinstance(alpha_div, (int, float)) else "N/A"
    finnhub_div = finnhub_div if isinstance(finnhub_div, (int, float)) else "N/A"

    prompt = f"""
    Pr√ºfe folgende Dividendenrenditen:
    - Yahoo Finance: {yahoo_div if yahoo_div != 'N/A' else 'unrealistisch'}%
    - Alpha Vantage: {alpha_div if alpha_div != 'N/A' else 'unrealistisch'}%
    - Finnhub: {finnhub_div if finnhub_div != 'N/A' else 'unrealistisch'}%

    Entscheide, welche Dividendenrendite realistisch ist, und gib pr√§gnant an:
    "Yahoo", "Alpha Vantage", "Finnhub" oder "Keiner", falls alle unrealistisch sind.
    Liefere kurz eine Begr√ºndung dazu.
    """

    response = openai.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": "Du validierst Dividenden gewissenhaft und pr√§zise."},
            {"role": "user", "content": prompt}
        ]
    )

    validated_response = response.choices[0].message.content.strip()

    if "Keiner" in validated_response or all(div == "N/A" or (isinstance(div, (int, float)) and div > 20.0)
                                             for div in [yahoo_div, alpha_div, finnhub_div]):
        validated_response += "\n\n‚ö†Ô∏è Hinweis: Keine zuverl√§ssigen Dividendeninformationen verf√ºgbar. Bitte manuell pr√ºfen!"

    return validated_response

def analyse_sentiment(ticker, full_name):
    try:
        sources = ['Yahoo Finance', 'MarketWatch', 'Google News', 'Reuters', 'Finviz', 'Social Media']
        sentiment_results = {}

        for source in sources:
            # hier sollte der echte API-Call stehen
            sentiment_results[source] = "neutral"

        # GPT-Validierung
        final_sentiment = validate_sentiment_gpt(sentiment_results)

        return {"Final (GPT-Validiert)": final_sentiment, **sentiment_results}

    except Exception as e:
        logging.error(f"Fehler bei Sentimentanalyse {ticker}: {str(e)}")
        return {
            'Final (GPT-Validiert)': 'nicht verf√ºgbar',
            'Fehler': f"Sentimentdaten nicht verf√ºgbar: {str(e)}"
        }

import openai

def validate_sentiment_gpt(sentiments):
    prompt = f"""
    Du erh√§ltst folgende Sentiment-Daten aus verschiedenen Quellen:
    {sentiments}

    Analysiere diese kurz und entscheide dich f√ºr eine finale Sentiment-Einsch√§tzung:
    positiv, negativ oder neutral.

    Gib nur das finale Sentiment zur√ºck.
    """

    response = openai.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": "Du bist ein Sentiment-Analyse-Experte."},
            {"role": "user", "content": prompt}
        ]
    )

    validated_sentiment = response.choices[0].message.content.strip().lower()

    # Sicherstellen, dass die Antwort immer g√ºltig ist
    if validated_sentiment not in ["positiv", "negativ", "neutral"]:
        validated_sentiment = "neutral"

    return validated_sentiment

def predict_stock_price(df, days_to_predict=30, prediction_days=60, epochs=50):
    try:
        data = df['Close'].values.reshape(-1, 1)
        scaler = MinMaxScaler()
        scaled_data = scaler.fit_transform(data)

        x_train, y_train = [], []

        for i in range(prediction_days, len(scaled_data)):
            x_train.append(scaled_data[i-prediction_days:i, 0])
            y_train.append(scaled_data[i, 0])

        x_train, y_train = np.array(x_train), np.array(y_train)
        x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))

        model = Sequential()
        model.add(Input(shape=(x_train.shape[1], 1)))
        model.add(LSTM(units=50, activation='relu'))
        model.add(Dense(1))
        model.compile(optimizer='adam', loss='mean_squared_error')

        model.fit(x_train, y_train, epochs=epochs, batch_size=32, verbose=0)

        # Prognose erstellen
        last_days = scaled_data[-prediction_days:]
        prediction_list = []

        for _ in range(days_to_predict):
            pred_input = last_days[-prediction_days:].reshape(1, prediction_days, 1)
            pred = model.predict(pred_input, verbose=0)[0, 0]
            prediction_list.append(pred)
            last_days = np.append(last_days, pred)

        predicted_prices = scaler.inverse_transform(np.array(prediction_list).reshape(-1, 1))
        return predicted_prices.flatten().tolist()

    except Exception as e:
        logging.error(f"Fehler bei Prognoseberechnung: {str(e)}")
        return ["Prognosedaten nicht verf√ºgbar"]

def predict_crypto_price(prices, days_to_predict=30, prediction_days=60, epochs=50):
    data = np.array(prices).reshape(-1, 1)
    scaler = MinMaxScaler()
    scaled_data = scaler.fit_transform(data)

    x_train, y_train = [], []

    for i in range(prediction_days, len(scaled_data)):
        x_train.append(scaled_data[i-prediction_days:i, 0])
        y_train.append(scaled_data[i, 0])

    x_train, y_train = np.array(x_train), np.array(y_train)
    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))

    model = Sequential()
    model.add(Input(shape=(x_train.shape[1], 1)))
    model.add(LSTM(units=50, activation='relu'))
    model.add(Dense(1))
    model.compile(optimizer='adam', loss='mean_squared_error')

    model.fit(x_train, y_train, epochs=epochs, batch_size=32, verbose=0)

    last_days = scaled_data[-prediction_days:]
    prediction_list = []

    for _ in range(days_to_predict):
        pred_input = last_days[-prediction_days:].reshape(1, prediction_days, 1)
        pred = model.predict(pred_input, verbose=0)[0, 0]
        prediction_list.append(pred)
        last_days = np.append(last_days, pred)

    predicted_prices = scaler.inverse_transform(np.array(prediction_list).reshape(-1, 1))
    return predicted_prices.flatten().tolist()

import requests

NZ_API_KEY = 'e05547e888cf413e91fc9f7b40eb5085'
NZ_CPI_ENDPOINT = "https://api.stats.govt.nz/opendata/v1/ConsumersPriceIndex/Observations?$top=1"

headers = {'Ocp-Apim-Subscription-Key': NZ_API_KEY}

def get_nz_inflation():
    response = requests.get(NZ_CPI_ENDPOINT, headers=headers)
    if response.status_code == 200:
        data = response.json()
        latest_observation = data['items'][0]
        inflation_rate = latest_observation['value']
        return inflation_rate
    else:
        raise Exception(f"API Fehler: {response.status_code} - {response.text}")

from alpha_vantage.fundamentaldata import FundamentalData
import openai
import logging

API_KEY = "87WSBSVKINDJN89S"
fd = FundamentalData(key=API_KEY, output_format='json')

def get_rating_alpha_vantage(ticker):
    try:
        data, _ = fd.get_company_overview(symbol=ticker)
        rating = data.get('CreditRating', 'N/A')
        return rating
    except Exception as e:
        logging.error(f"Fehler Alpha Vantage Rating {ticker}: {str(e)}")
        return "N/A"

def gpt_rating_fallback(entity):
    prompt = f"Wie lautet das aktuelle Kreditrating (S&P, Moody‚Äôs, Fitch) von {entity}? Gib nur die Rating-Stufen an (z.B. AA+, Baa1, BBB)."

    response = openai.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": "Nenne nur die aktuelle Rating-Stufe ohne weitere Erkl√§rungen."},
            {"role": "user", "content": prompt}
        ]
    )
    return response.choices[0].message.content.strip()

from alpha_vantage.timeseries import TimeSeries
import pandas as pd

API_KEY = "87WSBSVKINDJN89S"

def get_commodity_data(symbol, interval='daily'):
    ts = TimeSeries(key=API_KEY, output_format='pandas')
    data, meta_data = ts.get_daily(symbol=symbol, outputsize='compact')
    data.rename(columns={
        '1. open': 'Open',
        '2. high': 'High',
        '3. low': 'Low',
        '4. close': 'Close',
        '5. volume': 'Volume'
    }, inplace=True)
    return data

# Symbole f√ºr Alpha Vantage Rohstoffe:
symbols = {
    "Gold": "XAUUSD",
    "Silber": "XAGUSD",
    "Kupfer": "HGUSD",
    "Brent √ñl": "BNO",
    "WTI √ñl": "WTI",
    "Erdgas": "NG"
}

import openai

def get_commodity_sentiment(rohstoff, preis_trend):
    prompt = f"""
    Der Rohstoff ist {rohstoff}. Der aktuelle Preistrend und Marktstatus ist:
    {preis_trend}

    Fasse die aktuelle Marktentwicklung kurz zusammen und erl√§utere wichtige Einfl√ºsse auf den Markt in maximal 2-3 S√§tzen.
    """

    response = openai.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": "Du bist ein Rohstoffmarkt-Analyst."},
            {"role": "user", "content": prompt}
        ]
    )

    return response.choices[0].message.content.strip()

import tweepy
import openai

# Twitter API Credentials
client = tweepy.Client(bearer_token='AAAAAAAAAAAAAAAAAAAAAHos1AEAAAAA1ZsP%2BdYDkCODOZgZWtIkqA4fHHk%3DGaJ0Fw0N3XTDBBQ1TzVQL3vofsssUcvI8bbfs1gjinuPwPH8xj')

def get_twitter_sentiment(keyword, num_tweets=100):
    tweets = client.search_recent_tweets(query=keyword, max_results=num_tweets)

    texts = [tweet.text for tweet in tweets.data]

    prompt = f"Analysiere das allgemeine Sentiment aus diesen Tweets zu {keyword}: {texts}"

    response = openai.chat.completions.create(
        model="gpt-4o",
        messages=[{"role": "system", "content": "Analysiere pr√§zise das Sentiment (positiv, neutral, negativ)."},
                  {"role": "user", "content": prompt}]
    )

    sentiment = response.choices[0].message.content.strip()
    return sentiment

import praw
import openai

# Reddit API Credentials
reddit = praw.Reddit(
    client_id='pEisL0zyijPiObFfsCEHZA',
    client_secret='T-G5cCdVtlAultzgMA1kjz85dVJEaQ',
    user_agent='MySentimentAnalysisApp/0.1 by Desperate-Date7971'
)

def get_reddit_sentiment(subreddit_name, keyword, num_posts=100):
    subreddit = reddit.subreddit(subreddit_name)
    posts = subreddit.search(keyword, limit=num_posts)

    texts = [post.title + " " + post.selftext for post in posts]

    prompt = f"Analysiere das allgemeine Sentiment aus diesen Reddit-Posts zu {keyword}: {texts}"

    response = openai.chat.completions.create(
        model="gpt-4o",
        messages=[{"role": "system", "content": "Analysiere pr√§zise das Sentiment (positiv, neutral, negativ)."},
                  {"role": "user", "content": prompt}]
    )

    sentiment = response.choices[0].message.content.strip()
    return sentiment

from flask import Flask, jsonify
from pyngrok import ngrok
import logging
from fredapi import Fred
import numpy as np
import requests
from bs4 import BeautifulSoup
import openai
import praw
import tweepy

app = Flask(__name__)

# --- Analyse-Endpunkte ---

@app.route('/analyse/<asset_type>/<ticker>/<full_name>')
def analyse(asset_type, ticker, full_name):
    try:
        fundamentals = {}
        prognose = []

        if asset_type.lower() == 'crypto':
            prices = get_crypto_data(ticker)
            prognose = predict_crypto_price(prices)

        elif asset_type.lower() == 'etf':
            data = get_etf_data(ticker)
            prognose = predict_stock_price(data)

        elif asset_type.lower() == 'bond':
            data = get_bond_data(ticker)
            prognose = predict_stock_price(data)

        else:  # Aktien (Standardfall)
            data = get_stock_data(ticker)
            fundamentals = get_fundamentals(ticker, full_name)
            prognose = predict_stock_price(data)

        sentiment = analyse_sentiment(ticker, full_name)

        return jsonify({
            "fundamentals": fundamentals,
            "sentiment": sentiment,
            "prognose": prognose
        })

    except Exception as e:
        logging.error(f"Allgemeiner Fehler bei Analyse f√ºr {ticker}: {str(e)}")
        return jsonify({"Fehler": f"Analyse fehlgeschlagen: {str(e)}"}), 500


# --- OECD Inflation Integration ---

OECD_COUNTRY_CODES = {
    "frankreich": "FRA",
    "italien": "ITA",
    "kanada": "CAN",
    "suedkorea": "KOR",
    "australien": "AUS",
    "neuseeland": "NZL"
}

INFLATION_CONFIG_FRED = {
    "usa": ("CPIAUCSL", "USA"),
    "eurozone": ("CP0000EZ19M086NEST", "Eurozone (aggregiert)"),
    "deutschland": ("DEUCPIALLMINMEI", "Deutschland"),
    "gb": ("GBRCPIALLMINMEI", "Vereinigtes K√∂nigreich"),
    "japan": ("JPNCPIALLMINMEI", "Japan"),
    "china": ("CHNCPIALLMINMEI", "China"),
    "brasilien": ("BRACPIALLMINMEI", "Brasilien"),
}

def get_oecd_inflation(country_code):
    headers = {'Accept': 'application/json'}
    url = f"https://stats.oecd.org/SDMX-JSON/data/PRICES_CPI/{country_code}.CPALTT01.GY.M/all?lastNObservations=1"
    response = requests.get(url, headers=headers)
    response.raise_for_status()
    data = response.json()
    try:
        observations = data['dataSets'][0]['series']['0:0:0:0']['observations']
        latest_key = max(observations.keys(), key=int)
        return observations[latest_key][0]
    except (KeyError, IndexError) as e:
        raise ValueError(f"OECD Datenstruktur unerwartet: {e}")

# GPT-Fallback bei OECD Fehler
def gpt_inflation_fallback(region):
    prompt = f"Wie hoch ist aktuell die Inflationsrate in {region.capitalize()}? Bitte nenne nur die Zahl in Prozent."
    response = openai.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": "Gib nur die Inflationsrate in Prozent zur√ºck."},
            {"role": "user", "content": prompt}
        ]
    )
    return response.choices[0].message.content.strip()

@app.route('/makro/inflation/<region>')
def inflation(region):
    region = region.lower()

    if region in INFLATION_CONFIG_FRED:
        series_id, display_name = INFLATION_CONFIG_FRED[region]
        try:
            data = fred.get_series(series_id).dropna()
            if len(data) < 13:
                raise ValueError("Nicht gen√ºgend Datenpunkte zur Berechnung")
            inflation_rate = ((data.iloc[-1] - data.iloc[-13]) / data.iloc[-13]) * 100

            return jsonify({
                "Land": display_name,
                "Inflationsrate (%)": round(inflation_rate, 2)
            })

        except Exception as e:
            logging.error(f"FRED Fehler ({region}): {str(e)}")
            return jsonify({"Fehler": f"FRED Datenfehler: {str(e)}"}), 500

    elif region in OECD_COUNTRY_CODES:
        try:
            inflation_rate = get_oecd_inflation(OECD_COUNTRY_CODES[region])
        except Exception as e:
            logging.error(f"OECD Fehler ({region}): {str(e)}")
            inflation_rate = gpt_inflation_fallback(region)

        return jsonify({
            "Land": region.capitalize(),
            "Inflationsrate (%)": inflation_rate
        })

    else:
        return jsonify({"Fehler": "Region nicht unterst√ºtzt oder Daten unzureichend"}), 400

# Leitzinsimplementierung

LEITZINS_CONFIG_FRED = {
    "usa": ("FEDFUNDS", "USA"),
    "eurozone": ("ECBMRRFR", "Eurozone"),
    "gb": ("BOERUKM", "Gro√übritannien"),
    "japan": ("IRSTCI01JPM156N", "Japan")
}

@app.route('/makro/leitzins/<region>')
def leitzins(region):
    region = region.lower()

    if region in LEITZINS_CONFIG_FRED:
        series_id, display_name = LEITZINS_CONFIG_FRED[region]
        try:
            data = fred.get_series(series_id).dropna()
            leitzins = data.iloc[-1]

            return jsonify({
                "Land": display_name,
                "Leitzins (%)": round(leitzins, 2)
            })

        except Exception as e:
            logging.error(f"FRED Fehler (Leitzins {region}): {str(e)}")
            # Fallback via GPT, falls FRED scheitert
            leitzins = gpt_leitzins_fallback(region)

    else:
        # Region nicht in FRED, direkte GPT-Abfrage
        leitzins = gpt_leitzins_fallback(region)

    return jsonify({
        "Land": region.capitalize(),
        "Leitzins (%)": leitzins
    })

def gpt_leitzins_fallback(region):
    prompt = f"Wie hoch ist aktuell der Leitzins in {region.capitalize()}? Bitte gib ausschlie√ülich die Zahl in Prozent an."
    response = openai.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": "Gib nur den aktuellen Leitzins in Prozent an, ohne weitere Erkl√§rungen."},
            {"role": "user", "content": prompt}
        ]
    )
    return response.choices[0].message.content.strip()

# Politische Statements

@app.route('/politik/<land>/<person>', methods=['GET'])
def politisches_sentiment(land, person):
    try:
        prompt = f"Bewerte kurz, ob die aktuellsten Aussagen von {person.capitalize()} in {land.capitalize()} eher positive, negative oder neutrale Auswirkungen auf die Finanzm√§rkte haben. Gib nur an: 'positiv', 'negativ' oder 'neutral', plus eine kurze Begr√ºndung."

        response = openai.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "Bewerte pr√§zise und knapp den Einfluss politischer Aussagen auf Finanzm√§rkte."},
                {"role": "user", "content": prompt}
            ]
        )

        sentiment = response.choices[0].message.content.strip()

        return jsonify({
            "Person": person.capitalize(),
            "Land": land.capitalize(),
            "Sentiment": sentiment
        })

    except Exception as e:
        logging.error(f"Fehler bei politischem Sentiment f√ºr {person} in {land}: {str(e)}")
        return jsonify({"Fehler": f"Sentiment nicht verf√ºgbar: {str(e)}"}), 500

# Handelskonflikte

@app.route('/handel/<land1>/<land2>', methods=['GET'])
def handelskonflikte(land1, land2):
    try:
        prompt = f"Bewerte kurz die aktuellen Handelsbeziehungen zwischen {land1.capitalize()} und {land2.capitalize()}. Gib an, ob diese Handelskonflikte oder Zollma√ünahmen eher positiv, negativ oder neutral auf die globalen M√§rkte wirken k√∂nnten. Antworte mit 'positiv', 'negativ' oder 'neutral' sowie einer kurzen Erkl√§rung."

        response = openai.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "Du bewertest Handelskonflikte und Zollma√ünahmen pr√§zise und knapp hinsichtlich ihrer Auswirkungen auf globale Finanzm√§rkte."},
                {"role": "user", "content": prompt}
            ]
        )

        handels_sentiment = response.choices[0].message.content.strip()

        return jsonify({
            "Land1": land1.capitalize(),
            "Land2": land2.capitalize(),
            "Handelskonflikt-Sentiment": handels_sentiment
        })

    except Exception as e:
        logging.error(f"Fehler bei Handelskonflikt-Abfrage {land1}-{land2}: {str(e)}")
        return jsonify({"Fehler": f"Sentiment nicht verf√ºgbar: {str(e)}"}), 500

# Rohstoffpreise und Lieferketten

@app.route('/rohstoffe/sentiment/<rohstoff>')
def rohstoff_sentiment(rohstoff):
    try:  # <-- hier fehlte try
        prompt = f"Wie ist aktuell der Markt f√ºr {rohstoff.capitalize()} einzusch√§tzen? Antworte mit 'steigend', 'fallend' oder 'stabil' plus kurze Begr√ºndung."
        response = openai.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "system", "content": "Analysiere pr√§zise den Rohstoffmarkt."},
                      {"role": "user", "content": prompt}]
        )
        markt_sentiment = response.choices[0].message.content.strip()
        return jsonify({
            "Rohstoff": rohstoff.capitalize(),
            "Marktentwicklung": markt_sentiment
        })

    except Exception as e:
        logging.error(f"Fehler bei Rohstoffabfrage {rohstoff}: {str(e)}")
        return jsonify({"Fehler": f"Rohstoffdaten nicht verf√ºgbar: {str(e)}"}), 500

# Rohtstoffpreisaktualit√§t

@app.route('/rohstoffe/preis/<commodity>')
def get_rohstoff(commodity):
    symbols = {
        "gold": "XAUUSD",
        "silber": "XAGUSD",
        "kupfer": "HGUSD",
        "brent": "BNO",
        "wti": "WTI",
        "erdgas": "NG"
    }
    symbol = symbols.get(commodity.lower())
    if symbol:
        data = get_commodity_data(symbol)
        latest = data.iloc[-1].to_dict()

        preis_trend = f"Preis: {latest['Close']} USD, Tagesver√§nderung: {latest['Close'] - latest['Open']} USD"
        markt_sentiment = get_commodity_sentiment(commodity, preis_trend)

        return jsonify({
            "Rohstoff": commodity.capitalize(),
            "Preisinfo": latest,
            "Marktentwicklung": markt_sentiment
        })
    else:
        return jsonify({"Fehler": "Rohstoff nicht gefunden"}), 404

# Insider-Trading-Aktivitaeten

@app.route('/insider/<ticker>', methods=['GET'])
def insider_trading(ticker):
    try:
        url = f'https://finnhub.io/api/v1/stock/insider-transactions?symbol={ticker}&token={FINNHUB_API_KEY}'
        response = requests.get(url)
        data = response.json()

        recent_trades = data.get('data', [])[:5]

        summary = "\n".join([
            f"{trade.get('name', 'Unbekannt')} - {trade.get('transactionType', 'N/A')} - "
            f"{trade.get('share', 'N/A')} shares am {trade.get('transactionDate', 'N/A')}"
            for trade in recent_trades
        ])

        gpt_response = openai.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "Analysiere kurz Insider-Trades hinsichtlich Markt-Signal."},
                {"role": "user", "content": f"Insider-Trades f√ºr {ticker}:\n{summary}\n\nSind diese Trades eher ein positives, negatives oder neutrales Signal?"}
            ]
        )

        insider_sentiment = gpt_response.choices[0].message.content.strip()

        return jsonify({
            "Ticker": ticker,
            "Insider-Trades": recent_trades,
            "Markt-Signal": insider_sentiment
        })

    except Exception as e:
        logging.error(f"Fehler Insider Trading {ticker}: {str(e)}")
        return jsonify({"Fehler": f"Insiderdaten nicht verf√ºgbar: {str(e)}"}), 500

# Rating-Agenturen

@app.route('/rating/<ticker>', methods=['GET'])
def rating(ticker):
    rating_av = get_rating_alpha_vantage(ticker)
    if rating_av == "N/A":
        rating_av = gpt_rating_fallback(ticker)

    return jsonify({
        "Ticker": ticker,
        "Rating": rating_av
    })

# Reddit Anbindung
import praw

reddit = praw.Reddit(
    client_id='pEisL0zyijPiObFfsCEHZA',               # deine Client ID
    client_secret='T-G5cCdVtlAultzgMA1kjz85dVJEaQ',     # dein Client Secret
    user_agent='MySentimentAnalysisApp/0.1 by Desperate-Date7971'  # dein User-Agent
)

@app.route('/sentiment/reddit/<string:subreddit_name>/<string:keyword>')
def reddit_sentiment(subreddit_name, keyword):
    try:
        subreddit = reddit.subreddit(subreddit_name)
        posts = subreddit.search(keyword, limit=50)

        texts = [f"{post.title} {post.selftext}" for post in posts]

        if not texts:
            return jsonify({
                "subreddit": subreddit_name,
                "keyword": keyword,
                "sentiment": "Keine relevanten Beitr√§ge gefunden.",
                "beispiele": []
            })

        # GPT-Sentimentanalyse
        prompt = f"""
        Analysiere das allgemeine Sentiment (positiv, neutral, negativ) der folgenden Reddit-Beitr√§ge zum Thema "{keyword}":
        {texts}

        Gib pr√§gnant zur√ºck: "positiv", "neutral" oder "negativ" plus kurze Begr√ºndung.
        """

        response = openai.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "Analysiere das Sentiment der Reddit-Beitr√§ge pr√§zise und knapp."},
                {"role": "user", "content": prompt}
            ]
        )

        sentiment = response.choices[0].message.content.strip()

        return jsonify({
            "subreddit": subreddit_name,
            "keyword": keyword,
            "sentiment": sentiment,
            "beispiele": texts[:5]  # Die ersten 5 Beitr√§ge als Beispiele
        })

    except Exception as e:
        logging.error(f"Fehler bei Reddit-Sentiment f√ºr {subreddit_name}/{keyword}: {str(e)}")
        return jsonify({"Fehler": f"Sentimentanalyse fehlgeschlagen: {str(e)}"}), 500

# Twitter Anbindung - geht nicht wg free account

@app.route('/twitter/test')
def twitter_test():
    import tweepy

    consumer_key="YWI2w1jZPre0geoaRw2bJK6xN"
    consumer_secret="p2QwLzLBVFiXkyOrhHpvWc3WqgZgk95lmA7DndkCnX2HvOeABi"
    access_token="1919114015588151296-sVoAim99ff3wg2t7u0AnWBAitjGNeS"
    access_token_secret="gAmwGxwdDyS75enwiniqZPwVoGjj7val6S5LJ3lpTsYNJ"

    auth = tweepy.OAuth1UserHandler(
        consumer_key, consumer_secret,
        access_token, access_token_secret
    )
    api = tweepy.API(auth)

    try:
        tweets = api.home_timeline(count=1)
        if tweets:
            return jsonify({"status": "‚úÖ Twitter API funktioniert!", "tweet": tweets[0].text})
        else:
            return jsonify({"status": "‚ö†Ô∏è Twitter API erreichbar, aber keine Tweets gefunden."})
    except Exception as e:
        logging.error(f"Twitter-API Fehler: {str(e)}")
        return jsonify({"status": "‚ùå Fehler", "message": str(e)}), 500

# --- Hauptausf√ºhrung ---

if __name__ == '__main__':
    public_url = ngrok.connect(5000).public_url
    print("üîó ngrok URL:", public_url)
    app.run()

